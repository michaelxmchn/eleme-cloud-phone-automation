#!/usr/bin/env python3
"""
é¥¿äº†ä¹ˆå•†å®¶ç‰ˆ - OCRè¯†åˆ«è§£å†³æ–¹æ¡ˆ
é€šè¿‡æˆªå›¾+OCRè¯†åˆ«æ–‡å­—ä½ç½®ï¼Œç„¶åç‚¹å‡»
"""

import subprocess
import time
import os
import sys
import json
from pathlib import Path

# å°è¯•å¯¼å…¥OCRåº“
try:
    import pytesseract
    from PIL import Image
    HAS_OCR = True
except ImportError:
    HAS_OCR = False
    print("âš ï¸ OCRåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åæ ‡ç‚¹å‡»")

# é…ç½®
CLOUD_PHONE_HOST = "127.0.0.1"
CLOUD_PHONE_PORT = "52849"
DEVICE = f"{CLOUD_PHONE_HOST}:{CLOUD_PHONE_PORT}"


class ElemeOCRController:
    def __init__(self, device=DEVICE):
        self.device = device
        self.screen_size = (1080, 1920)
        self.last_screenshot = "screenshot.png"
    
    def _run(self, cmd, timeout=30):
        result = subprocess.run(
            cmd, shell=True, capture_output=True, text=True, timeout=timeout
        )
        return result.stdout, result.stderr, result.returncode
    
    def connect(self):
        print(f"ğŸ”Œ è¿æ¥: {self.device}")
        stdout, _, _ = self._run(f"adb connect {self.device}")
        print(f"   {stdout.strip()}")
    
    def screenshot(self, filename=None):
        if filename:
            self.last_screenshot = filename
        print(f"ğŸ“¸ æˆªå›¾: {self.last_screenshot}")
        self._run(f"adb -s {self.device} shell screencap -p /sdcard/screen.png")
        self._run(f"adb -s {self.device} pull /sdcard/screen.png {self.last_screenshot}")
        return os.path.exists(self.last_screenshot)
    
    def get_screen_size(self):
        stdout, _, _ = self._run(f"adb -s {self.device} shell wm size")
        if "x" in stdout:
            size = stdout.strip().split(" ")[-1]
            w, h = size.split("x")
            self.screen_size = (int(w), int(h))
        return self.screen_size
    
    def find_text(self, text, exact=False):
        """OCRæŸ¥æ‰¾æ–‡å­—ä½ç½®"""
        if not HAS_OCR:
            print("âŒ éœ€è¦å®‰è£…OCRåº“: pip install pytesseract pillow")
            return None
        
        if not os.path.exists(self.last_screenshot):
            self.screenshot()
        
        # è¯»å–å›¾ç‰‡
        img = Image.open(self.last_screenshot)
        
        # OCRè¯†åˆ«
        data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT)
        
        # æŸ¥æ‰¾åŒ¹é…çš„æ–‡æœ¬
        matches = []
        n = len(data["text"])
        
        for i in range(n):
            txt = data["text"][i]
            if text in txt or (exact and txt == text):
                x = int(data["left"][i] + data["width"][i] / 2)
                y = int(data["top"][i] + data["height"][i] / 2)
                confidence = data["conf"][i]
                matches.append({
                    "text": txt,
                    "x": x,
                    "y": y,
                    "confidence": confidence
                })
        
        if matches:
            print(f"âœ… æ‰¾åˆ°'{text}': {len(matches)}ä¸ªä½ç½®")
            for m in matches:
                print(f"   - {m['text']}: ({m['x']}, {m['y']}) ç½®ä¿¡åº¦:{m['confidence']}")
            return matches[0]  # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…
        
        print(f"âŒ æœªæ‰¾åˆ°'{text}'")
        return None
    
    def tap_text(self, text):
        """ç‚¹å‡»æ–‡å­—ï¼ˆé€šè¿‡OCRå®šä½ï¼‰"""
        pos = self.find_text(text)
        if pos:
            return self.tap(pos["x"], pos["y"])
        return False
    
    def tap(self, x, y):
        """ç‚¹å‡»"""
        print(f"ğŸ‘† ç‚¹å‡»: ({x}, {y})")
        
        # æ–¹æ³•1: input tap
        self._run(f"adb -s {self.device} shell input tap {x} {y}")
        
        # æ–¹æ³•2: motioneventåºåˆ—ï¼ˆæ›´å¯é ï¼‰
        time.sleep(0.1)
        self._run(f"adb -s {self.device} shell input motionevent DOWN {x} {y}")
        time.sleep(0.05)
        self._run(f"adb -s {self.device} shell input motionevent UP {x} {y}")
        
        time.sleep(0.3)
        return True
    
    def swipe(self, x1, y1, x2, y2, duration=500):
        """æ»‘åŠ¨"""
        print(f"ğŸ‘† æ»‘åŠ¨: ({x1},{y1}) -> ({x2},{y2})")
        
        # åˆ†æ­¥æ»‘åŠ¨
        steps = 20
        for i in range(steps + 1):
            x = int(x1 + (x2 - x1) * i / steps)
            y = int(y1 + (y2 - y1) * i / steps)
            self._run(f"adb -s {self.device} shell input motionevent {'MOVE' if i > 0 else 'DOWN'} {x} {y}")
            time.sleep(duration / steps / 1000)
        
        self._run(f"adb -s {self.device} shell input motionevent UP {x2} {y2}")
        time.sleep(0.3)
        return True
    
    def input_text(self, text):
        """è¾“å…¥æ–‡å­—"""
        print(f"âŒ¨ï¸ è¾“å…¥: {text}")
        text = text.replace(" ", "%s")
        self._run(f"adb -s {self.device} shell input text {text}")
        time.sleep(0.3)
    
    def back(self):
        self._run(f"adb -s {self.device} shell input keyevent 4")
        time.sleep(0.3)


def install_ocr():
    """å®‰è£…OCRä¾èµ–"""
    print("å®‰è£…OCRä¾èµ–...")
    os.system("pip install pytesseract pillow -q")
    print("âœ… å®‰è£…å®Œæˆ")


if __name__ == "__main__":
    if not HAS_OCR:
        print("âš ï¸ OCRæœªå®‰è£…ï¼Œè¦å®‰è£…å—ï¼Ÿ(y/n)")
        # install_ocr()
    
    controller = ElemeOCRController()
    controller.connect()
    controller.get_screen_size()
    
    # æµ‹è¯•æˆªå›¾
    controller.screenshot()
    
    # å¦‚æœå®‰è£…äº†OCRï¼Œå¯ä»¥æŸ¥æ‰¾æ–‡å­—
    if HAS_OCR:
        # ç¤ºä¾‹: æŸ¥æ‰¾"ç¡®è®¤"æŒ‰é’®
        # controller.find_text("ç¡®è®¤")
        pass
    
    print("\nâœ… åˆå§‹åŒ–å®Œæˆ")
